{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e205e0c",
   "metadata": {},
   "source": [
    "# Implementation of Text Level Graph Neural Network for Text Classification\n",
    "Here, I am implementing a research paper titled <i>Text Level Graph Neural Network for Text Classification</i> which can be found [here](https://arxiv.org/pdf/1910.02356.pdf). Previous GNN-based methods of text classification involved creating a single graph for the entire corpus, which caused two major problems. First, this results in high memory consumption and is impractical for larger graphs. Second, it is very difficult to apply these models to new data, because the structure and parameters of the graph is dependent on the corpus and cannot be modified after training.\n",
    "\n",
    "This paper tackles these problems by building graphs for each input text rather than a single graph for the entire corpus. The representations and edge weights of the same node are shared globally and are updated through a message passing mechanism where a node uses information from neighboring nodes to update its representation. Additionally, the word nodes in the graph are connected within a reasonably small window in the text rather than fully connecting all word nodes. Predictions are made by summarizing the representations of all the nodes in the graph.\n",
    "\n",
    "## Practical Use-Cases\n",
    "<ul>\n",
    "        <li> spam detection\n",
    "        <li> fake news detection\n",
    "        <li> tagging content or products by using categories as a way to improve browsing or identify related content on the website. This can be used in ecommerce and with news agencies, content curators, blogs, and directories\n",
    "        <li> a faster emergency response system can be made by classifying panic conversation on social media\n",
    "        <li> marketers can monitor and classify users based on how they talk about a product or brand online\n",
    "        <li> academia, law practitioners, social researchers, government, and non-profit organizations deal with a lot of unstructured text, handling the data would be much easier if it were standardized by categories/tags\n",
    "        <li> sentiment analysis\n",
    "        <li> organizations need to classify documents so that their text data is easier to manage and utilize such as classifying incoming customer support tickets so they get sent to the right customer\n",
    "            \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59c3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from time import time\n",
    "import argparse\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f5765",
   "metadata": {},
   "source": [
    "## GloveTokenizer\n",
    "Below, I'm using the GloVe tokenizer. it is introduced by Jeffrey Pennington, Richard Socher, Christopher D. Manning in 2014 in a paper titled <i> GloVe: Global Vectors for Word Representation </i> which can be found [here](https://nlp.stanford.edu/pubs/glove.pdf). GloVe is a count-based, unsupervised learning model that uses co-occurrence (how frequently two words appear together) statistics at a Global level to model the vector representations of words. Since the statistics are captured at a global level directly by the model, it is named the Global Vectors model.\n",
    "\n",
    "Here, I'm using the glove.6B.300d embeddings which is a .txt file where, on every line, the first entry is the word and the following 300 entries are the embedding. I define functions to encode strings, decode a list of integers, and and to get the embedding array from a list of integers. The file can be downloaded [here](https://www.kaggle.com/thanakomsn/glove6b300dtxt). I'm using the 300d GloVe embeddings, since that was what was used in the research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e47393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveTokenizer:\n",
    "    def __init__(self, filename, unk='<unk>', pad='<pad>'):\n",
    "        self.filename = filename\n",
    "        self.unk = unk # unknown token\n",
    "        self.pad = pad # pad token\n",
    "        self.stoi = dict() # string to int dictionary\n",
    "        self.itos = dict() # int to string dictionary\n",
    "        self.embedding_matrix = list() # contains the embeddings\n",
    "        with open(filename, 'r', encoding='utf8') as f: # Read tokenizer file\n",
    "            for i, line in enumerate(f):\n",
    "                values = line.split()\n",
    "                # the first value in each line is the string, the rest of the values in the line is the embedding\n",
    "                self.stoi[values[0]] = i\n",
    "                self.itos[i] = values[0]\n",
    "                self.embedding_matrix.append([float(v) for v in values[1:]])\n",
    "        if self.unk is not None: # Add unk token into the tokenizer\n",
    "            i += 1\n",
    "            self.stoi[self.unk] = i\n",
    "            self.itos[i] = self.unk\n",
    "            # embeddings are random numbers between 0-1\n",
    "            self.embedding_matrix.append(np.random.rand(len(self.embedding_matrix[0]))) \n",
    "        if self.pad is not None: # Add pad token into the tokenizer\n",
    "            i += 1\n",
    "            self.stoi[self.pad] = i\n",
    "            self.itos[i] = self.pad\n",
    "            # embeddings are all 0's\n",
    "            self.embedding_matrix.append(np.zeros(len(self.embedding_matrix[0]))) \n",
    "        # Convert from double to float for efficiency\n",
    "        self.embedding_matrix = np.array(self.embedding_matrix).astype(np.float32) \n",
    "\n",
    "    # to encode a string into numbers\n",
    "    def encode(self, sentence):\n",
    "        if type(sentence) == str:\n",
    "            # splits the string by \" \" and also, include punctuation since Glove has embeddings for punctuation\n",
    "            sentence = re.findall(r\"[\\w']+|[.,!?;]\", sentence)\n",
    "        elif len(sentence): # if it is not a string, but it is convertible to a list, then convert it\n",
    "            sentence = list(sentence)\n",
    "        else:\n",
    "            raise TypeError('sentence should be either a str or a list of str!')\n",
    "        encoded_sentence = list()\n",
    "        for word in sentence:\n",
    "            # encode each word using the string to int dictionary, if the word doesn't exist, use the unknown token\n",
    "            # converting the word to lower case since the stoi dictionary only has lower case words\n",
    "            # otherwise, all capitalized words would just be given the unknown token\n",
    "            encoded_sentence.append(self.stoi.get(word.lower(), self.stoi[self.unk])) \n",
    "        return encoded_sentence\n",
    "\n",
    "    # to decode numbers into a string\n",
    "    def decode(self, encoded_sentence):\n",
    "        try:\n",
    "            encoded_sentence = list(encoded_sentence)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise TypeError('encoded_sentence should be either a str or a data type that is convertible to list type!')\n",
    "        sentence = list()\n",
    "        for encoded_word in encoded_sentence:\n",
    "            sentence.append(self.itos[encoded_word])\n",
    "        return sentence\n",
    "\n",
    "    # takes an encoded sentence and returns the embeddings of shape (len(encoded_sentence), 300)\n",
    "    def embedding(self, encoded_sentence):\n",
    "        return self.embedding_matrix[np.array(encoded_sentence)]\n",
    "    \n",
    "# example:\n",
    "# tokenizer = GloveTokenizer('embeddings/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64554d",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "Here, I am using the R8 dataset. This is a subset of the Reuters-21578 dataset, which is a collection of documents with news articles. The Reuters-21578 dataset is one of the most widely used data collections for text categorization research. It is collected from the Reuters financial newswire service in 1987. The Reuters-21578 dataset has 10,369 documents and a vocabulary of 29,930 words. It can be found [here](https://paperswithcode.com/dataset/reuters-21578). The R8 dataset, which is implemented in the research paper, has 5,485 training examples and 2189 test examples and 8 classes. When the R8 dataset was created, it removed all numbers from the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47307432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earn</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  earn  champion products ch approves stock split cham...\n",
       "1   acq  computer terminal systems cpml completes sale ...\n",
       "2  earn  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3  earn  am international inc am nd qtr jan oper shr lo...\n",
       "4  earn  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filename='r8-train-all-terms.txt'\n",
    "test_filename='r8-test-all-terms.txt'\n",
    "train_data = pd.read_csv(train_filename, sep='\\t', header=None)\n",
    "test_data = pd.read_csv(test_filename, sep='\\t', header=None)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c62a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12309a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Tokens in Training Set: 105.28\n"
     ]
    }
   ],
   "source": [
    "average_length = list()\n",
    "for train_str in train_data[1]:\n",
    "    # splits each training string by \" \" and by punctuation, which is the same process of tokenization as in the GloVe tokenizer below\n",
    "    average_length.append(len(re.findall(r\"[\\w']+|[.,!?;]\", train_str)))\n",
    "print(f\"Average Number of Tokens in Training Set: {round(np.array(average_length).mean(),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4486cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_counts = train_data[0].value_counts()\n",
    "plt.bar(val_counts.index, val_counts)\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(\"Frequency of Labels in Training Set\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20f75eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to_numpy()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee599c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLevelGNNDatasetClass: # This class is used to achieve parameters sharing among datasets\n",
    "    def __init__(self, train_filename, test_filename, tokenizer, MAX_LENGTH=10, p=2, min_freq=2, train_validation_split=0.8):\n",
    "        self.train_filename = train_filename\n",
    "        self.test_filename = test_filename\n",
    "        self.tokenizer = tokenizer\n",
    "        self.MAX_LENGTH = MAX_LENGTH # The max length of each document to be processed\n",
    "        self.p = p # the window size\n",
    "        self.min_freq = min_freq # The minimum no. of occurrence for a word to be considered as a meaningful word. Words with less than this occurrence will be mapped to a globally shared embedding weight (to the <unk> token). It corresponds to the parameter k in the original paper\n",
    "        self.train_validation_split = train_validation_split\n",
    "\n",
    "        # read the training data\n",
    "        self.train_data = pd.read_csv(self.train_filename, sep='\\t', header=None)\n",
    "        self.test_data = pd.read_csv(self.test_filename, sep='\\t', header=None)\n",
    "\n",
    "        # this class has its own stoi and itos class which contains just the vocab in the training data\n",
    "        # and does NOT include the vocab in the validation data\n",
    "        # the first two values are the unknown and the pad\n",
    "        self.stoi = {'<unk>': 0, '<pad>': 1} # Re-index\n",
    "        self.itos = {0: '<unk>', 1: '<pad>'} # Re-index\n",
    "        self.vocab_count = len(self.stoi)\n",
    "        self.embedding_matrix = None\n",
    "        \n",
    "        # create a dictionary mapping labels to their one-hot encoded values\n",
    "        self.label_dict = dict(zip(self.train_data[0].unique(), pd.get_dummies(self.train_data[0].unique()).values.tolist()))\n",
    "\n",
    "        # split training data in to training and validation data\n",
    "        self.train_dataset, self.validation_dataset = random_split(self.train_data.to_numpy(), [int(len(self.train_data) * train_validation_split), len(self.train_data) - int(len(self.train_data) * train_validation_split)])\n",
    "        self.test_dataset = self.test_data.to_numpy()\n",
    "\n",
    "        # Based on train_dataset only. Updates self.stoi, self.itos, self.vocab_count and self.embedding_matrix\n",
    "        self.build_vocab() \n",
    "        \n",
    "        # this prepares the dataset\n",
    "        self.train_dataset, self.validation_dataset, self.test_dataset, self.edge_stat, self.public_edge_mask = self.prepare_dataset()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # getting list of all tokens\n",
    "        vocab_list = [re.findall(r\"[\\w']+|[.,!?;]\", sentence) for _, sentence in self.train_dataset]\n",
    "        unique_vocab = []\n",
    "        for vocab in vocab_list:\n",
    "            unique_vocab.extend(vocab)\n",
    "        # getting list of unique tokens\n",
    "        unique_vocab = [item.lower() for item in list(set(unique_vocab))]\n",
    "        for vocab in unique_vocab:\n",
    "            # converting the vocab word to lower case since the tokenizer does not recognize upper case\n",
    "            # if the vocab word is recognized by the tokenizer, add the vocab to stoi, itos, and increment vocab_count by 1\n",
    "            if vocab in self.tokenizer.stoi.keys():\n",
    "                # only add the vocab to the stoi keys and increment the vocab_count if the vocab isn't already in stoi\n",
    "                if vocab not in stoi.keys():\n",
    "                    self.stoi[vocab] = self.vocab_count\n",
    "                    self.itos[self.vocab_count] = vocab\n",
    "                    self.vocab_count += 1\n",
    "        # getting the embedding matrix for all strings in the vocabulary\n",
    "        self.embedding_matrix = self.tokenizer.embedding(self.tokenizer.encode(list(self.stoi.keys())))\n",
    "\n",
    "    def prepare_dataset(self): # will also build self.edge_stat and self.public_edge_mask\n",
    "        # preparing self.train_dataset\n",
    "        # gets the first MAX_LENGTH words from each sentence in train_dataset and converts them to ints\n",
    "        node_sets = [[self.stoi.get(vocab, 0) for vocab in re.findall(r\"[\\w']+|[.,!?;]\", sentence)][:self.MAX_LENGTH] for _, sentence in self.train_dataset] # Only retrieve the first MAX_LENGTH words in each document\n",
    "        # This function iterates through the nodeset and creates a neighborset which connects each node to the other nodes that are within the window of size p\n",
    "        neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\n",
    "        # gets the one-hot encoding of the labels\n",
    "        labels = [self.label_dict[label] for label, _ in self.train_dataset]\n",
    "\n",
    "        # Construct edge statistics and public edge mask\n",
    "        edge_stat, public_edge_mask = self.build_public_edge_mask(node_sets, neighbor_sets, min_freq=self.min_freq)\n",
    "        \n",
    "        train_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\n",
    "\n",
    "        # preparing self.validation_dataset\n",
    "        node_sets = [[self.stoi.get(vocab, 0) for vocab in sentence.strip().split(' ')][:self.MAX_LENGTH] for _, sentence in self.validation_dataset] # Only retrieve the first MAX_LENGTH words in each document\n",
    "        neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\n",
    "        labels = [self.label_dict[label] for label, _ in self.validation_dataset]\n",
    "        validation_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\n",
    "\n",
    "        # preparing self.test_dataset\n",
    "        node_sets = [[self.stoi.get(vocab, 0) for vocab in sentence.strip().split(' ')][:self.MAX_LENGTH] for _, sentence in self.test_dataset] # Only retrieve the first MAX_LENGTH words in each document\n",
    "        neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\n",
    "        labels = [self.label_dict[label] for label, _ in self.test_dataset]\n",
    "        test_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\n",
    "\n",
    "        return train_dataset, validation_dataset, test_dataset, edge_stat, public_edge_mask\n",
    "\n",
    "    def build_public_edge_mask_new(self, node_sets, neighbor_sets, min_freq=2):\n",
    "        # edge_stat is a torch.tensor that measures the edges of all vocab tokens with all other vocab tokens\n",
    "        edge_stat = torch.zeros(self.vocab_count, self.vocab_count)\n",
    "        for neighbor_set in neighbor_sets:\n",
    "            for neighbor in neighbor_set:\n",
    "                for to_node in neighbor:\n",
    "                    # all of the rows in node_set and in column to_node are increased by 1\n",
    "                    # create neighbors_temp which removes one single occurrence of to_node,\n",
    "                    # that way the edges only connect the same node with itself if it shows up multiple times in neighbor\n",
    "                    neighbors_temp = copy.deepcopy(neighbor)\n",
    "                    neighbors_temp.remove(to_node)\n",
    "                    # connect all neighbors to the node\n",
    "                    edge_stat[neighbors_temp, to_node] += 1\n",
    "                    # connect all nodes to the neighbors\n",
    "                    edge_stat[to_node, neighbors_temp] += 1\n",
    "        public_edge_mask = edge_stat < min_freq # mark True at uncommon edges\n",
    "        return edge_stat, public_edge_mask\n",
    "\n",
    "    def build_public_edge_mask(self, node_sets, neighbor_sets, min_freq=2):\n",
    "        # edge_stat is a torch.tensor that measures the edges of all vocab tokens with all other vocab tokens\n",
    "        edge_stat = torch.zeros(self.vocab_count, self.vocab_count)\n",
    "        for node_set, neighbor_set in zip(node_sets, neighbor_sets):\n",
    "            for neighbor in neighbor_set:\n",
    "                for to_node in neighbor:\n",
    "                    # all of the rows in node_set and in column to_node are increased by 1\n",
    "                    edge_stat[node_set, to_node] += 1\n",
    "        public_edge_mask = edge_stat < min_freq # mark True at uncommon edges\n",
    "        return edge_stat, public_edge_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774d059",
   "metadata": {},
   "source": [
    "## Instantiating train, validation, and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "357d3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLevelGNNDataset(Dataset): # For instantiating train, validation and test dataset\n",
    "    def __init__(self, node_sets, neighbor_sets, public_edge_mask, labels):\n",
    "        super(TextLevelGNNDataset).__init__()\n",
    "        self.node_sets = node_sets\n",
    "        self.neighbor_sets = neighbor_sets\n",
    "        self.public_edge_mask = public_edge_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.LongTensor(self.node_sets[i]), \\\n",
    "               torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1), \\\n",
    "               self.public_edge_mask[torch.LongTensor(self.node_sets[i]).unsqueeze(-1).repeat(1, torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1).shape[-1]), torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1)], \\\n",
    "               torch.FloatTensor(self.labels[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eafe096",
   "metadata": {},
   "source": [
    "## Create Neighbor Set Function\n",
    "This function iterates through the nodeset and creates a neighborset which connects each node to the other nodes that are within the window of size p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a260b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbor_set(node_set, p=2):\n",
    "    if type(node_set[0]) != int:\n",
    "        raise ValueError('node_set should be a 1D list!')\n",
    "    if p < 0:\n",
    "        raise ValueError('p should be an integer >= 0!')\n",
    "    sequence_length = len(node_set)\n",
    "    neighbor_set = []\n",
    "    for i in range(sequence_length):\n",
    "        neighbor = []\n",
    "        for j in range(-p, p+1):\n",
    "            if 0 <= i + j < sequence_length:\n",
    "                neighbor.append(node_set[i+j])\n",
    "        neighbor_set.append(neighbor)\n",
    "    return neighbor_set\n",
    "# example:\n",
    "# single_nodeset = [8145, 15469, 446, 6223, 5523, 4492, 8145, 11493, 11578, 9559]\n",
    "# create_neighbor_set(single_nodeset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13fc3f",
   "metadata": {},
   "source": [
    "## Padding Sequences and Tensors Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799b08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_custom_sequence(sequences):\n",
    "    '''\n",
    "    To pad different sequences into a padded tensor for training. The main purpose of this function is to separate different sequence, pad them in different ways and return padded sequences.\n",
    "    Input:\n",
    "        sequences <list>: A sequence with a length of 4, representing the node sets sequence in index 0, neighbor sets sequence in index 1, public edge mask sequence in index 2 and label sequence in index 3.\n",
    "                          And the length of each sequences are same as the batch size.\n",
    "                          sequences: [node_sets_sequence, neighbor_sets_sequence, public_edge_mask_sequence, label_sequence]\n",
    "    Return:\n",
    "        node_sets_sequence <torch.LongTensor>: The padded node sets sequence (works with batch_size >= 1).\n",
    "        neighbor_sets_sequence <torch.LongTensor>: The padded neighbor sets sequence (works with batch_size >= 1).\n",
    "        public_edge_mask_sequence <torch.BoolTensor>: The padded public edge mask sequence (works with batch_size >= 1).\n",
    "        label_sequence <torch.FloatTensor>: The padded label sequence (works with batch_size >= 1).\n",
    "    '''\n",
    "    node_sets_sequence = []\n",
    "    neighbor_sets_sequence = []\n",
    "    public_edge_mask_sequence = []\n",
    "    label_sequence = []\n",
    "    for node_sets, neighbor_sets, public_edge_mask, label in sequences:\n",
    "        node_sets_sequence.append(node_sets)\n",
    "        neighbor_sets_sequence.append(neighbor_sets)\n",
    "        public_edge_mask_sequence.append(public_edge_mask)\n",
    "        label_sequence.append(label)\n",
    "    node_sets_sequence = torch.nn.utils.rnn.pad_sequence(node_sets_sequence, batch_first=True, padding_value=1)\n",
    "    neighbor_sets_sequence, _ = padding_tensor(neighbor_sets_sequence)\n",
    "    public_edge_mask_sequence, _ = padding_tensor(public_edge_mask_sequence)\n",
    "    label_sequence = torch.nn.utils.rnn.pad_sequence(label_sequence, batch_first=True, padding_value=1)\n",
    "    return node_sets_sequence, neighbor_sets_sequence, public_edge_mask_sequence, label_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2c3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor(sequences, padding_idx=1):\n",
    "    '''\n",
    "    To pad tensor of different shape to be of the same shape, i.e. padding [tensor.rand(2, 3), tensor.rand(3, 5)] to a shape (2, 3, 5), where 0th dimension is batch_size, 1st and 2nd dimensions are padded.\n",
    "    Input:\n",
    "        sequences <list>: A list of tensors\n",
    "        padding_idx <int>: The index that corresponds to the padding index\n",
    "    Return:\n",
    "        out_tensor <torch.tensor>: The padded tensor\n",
    "        mask <torch.tensor>: A boolean torch tensor where 1 (represents '<pad>') are marked as true\n",
    "    '''\n",
    "    num = len(sequences)\n",
    "    max_len_0 = max([s.shape[0] for s in sequences])\n",
    "    max_len_1 = max([s.shape[1] for s in sequences])\n",
    "    out_dims = (num, max_len_0, max_len_1)\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_idx)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        len_0 = tensor.size(0)\n",
    "        len_1 = tensor.size(1)\n",
    "        out_tensor[i, :len_0, :len_1] = tensor\n",
    "    mask = out_tensor == padding_idx # Marking all places with padding_idx as mask\n",
    "    return out_tensor, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb645cef",
   "metadata": {},
   "source": [
    "# Message Passing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "486fd284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(nn.Module):\n",
    "    def __init__(self, vertice_count, input_size, out_size, dropout_rate=0, padding_idx=1):\n",
    "        super(MessagePassing, self).__init__()\n",
    "        self.vertice_count = vertice_count # |V|\n",
    "        self.input_size = input_size # d\n",
    "        self.out_size = out_size # c\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.padding_idx = padding_idx\n",
    "        self.information_rate = nn.Parameter(torch.rand(self.vertice_count, 1)) # (|V|, 1), which means it is a column vector\n",
    "        self.linear = nn.Linear(self.input_size, self.out_size) # (d, c)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "    def forward(self, node_sets, embedded_node, edge_weight, embedded_neighbor_node):\n",
    "        # node_sets: (batch_size, l)\n",
    "        # embedded_node: (batch_size, l, d)\n",
    "        # edge_weight: (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        # embedded_neighbor_node: (batch_size, max_sentence_length, max_neighbor_count, d)\n",
    "\n",
    "        tmp_tensor = (edge_weight.view(-1, 1) * embedded_neighbor_node.view(-1, self.input_size)).view(embedded_neighbor_node.shape) # (batch_size, max_sentence_length, max_neighbor_count, d)\n",
    "        tmp_tensor = tmp_tensor.masked_fill(tmp_tensor == 0, -1e18) # (batch_size, max_sentence_length, max_neighbor_count, d), mask for M such that masked places are marked as -1e18\n",
    "        tmp_tensor = self.dropout(tmp_tensor)\n",
    "        M = tmp_tensor.max(dim=2)[0] # (batch_size, max_sentence_length, d), which is same shape as embedded_node (batch_size, l, d)\n",
    "        information_rate = self.information_rate[node_sets] # (batch_size, l, 1)\n",
    "        information_rate = information_rate.masked_fill((node_sets == self.padding_idx).unsqueeze(-1), 1) # (batch_size, l, 1), Fill the information rate of the padding index as 1, such that new e_n = (1-i_r) * M + i_r * e_n = (1-1) * 0 + 1 * e_n = e_n (no update)\n",
    "        embedded_node = (1 - information_rate) * M + information_rate * embedded_node # (batch_size, l, d)\n",
    "        sum_embedded_node = embedded_node.sum(dim=1) # (batch_size, d)\n",
    "        x = F.relu(self.linear(sum_embedded_node)) # (batch_size, c)\n",
    "#         x = self.dropout(x) # if putting dropout with p=0.5 here, it is equivalent to wiping 4 choices out of 8 choices on the question sheet, which does not make sense. If a dropout layer is placed at here, it works the best when p=0 (disabled), followed by p=0.05, ..., p=0.5 (worst and does not even converge).\n",
    "        y = F.softmax(x, dim=1) # (batch_size, c) along the c dimension\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23edf1",
   "metadata": {},
   "source": [
    "## Building the GNN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13f20652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLevelGNN(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, out_size=8, dropout_rate=0, padding_idx=1):\n",
    "        super(TextLevelGNN, self).__init__()\n",
    "        self.out_size = out_size # c\n",
    "        self.padding_idx = padding_idx\n",
    "        self.weight_matrix = nn.Parameter(torch.randn(pretrained_embeddings.shape[0], pretrained_embeddings.shape[0])) # (|V|, |V|)        \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False, padding_idx=self.padding_idx) # (|V|, d)\n",
    "        self.message_passing = MessagePassing(vertice_count=pretrained_embeddings.shape[0], input_size=pretrained_embeddings.shape[1], out_size=self.out_size, dropout_rate=dropout_rate, padding_idx=self.padding_idx) # input_size: (d,); out_size: (c,)\n",
    "        self.public_edge_weight = nn.Parameter(torch.randn(1, 1)) # (1, 1)\n",
    "\n",
    "    def forward(self, node_sets, neighbor_sets, public_edge_mask):\n",
    "        # node_sets: (batch_size, l)\n",
    "        # neighbor_sets: (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        # neighbor_sets_mask: (batch_size, max_sentence_length, max_neighbor_count) (no need)\n",
    "        # public_edge_mask: (batch_size, max_sentence_length, max_neighbor_count)\n",
    "\n",
    "        embedded_node = self.embedding(node_sets) # (batch_size, l, d)\n",
    "        edge_weight = model.weight_matrix[node_sets.unsqueeze(2).repeat(1, 1, neighbor_sets.shape[-1]), neighbor_sets] # (batch_size, max_sentence_length, max_neighbor_count), neighbor_sets.shape[-1]: eg p=2, this expression=5; p=3, this expression=7. This is to first make node_sets to have same shape with neighbor_sets, then just do 1 query instead of 32*100 queries to speed up performance\n",
    "        a = edge_weight * ~public_edge_mask # (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        b = self.public_edge_weight.unsqueeze(2).expand(1, public_edge_mask.shape[-2], public_edge_mask.shape[-1]) * public_edge_mask # (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        edge_weight = a + b # (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        embedded_neighbor_node = self.embedding(neighbor_sets) # (batch_size, max_sentece_length, max_neighbor_count, d)\n",
    "\n",
    "        # Apply mask to edge_weight, to mask and cut-off any relationships to the padding nodes\n",
    "        edge_weight = edge_weight.masked_fill((node_sets.unsqueeze(2).repeat(1, 1, neighbor_sets.shape[-1]) == self.padding_idx) | (neighbor_sets == self.padding_idx), 0) # (batch_size, max_sentence_length, max_neighbor_count)\n",
    "        x = self.message_passing(node_sets, embedded_node, edge_weight, embedded_neighbor_node) # (batch_size, c)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5342d",
   "metadata": {},
   "source": [
    "## Setting up Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "efe30737",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'cuda':'0',\n",
    "       'embedding_size':300,\n",
    "       'p':3,\n",
    "       'min_freq':2,\n",
    "       'max_length':70,\n",
    "       'dropout':0,\n",
    "       'lr':1e-3,\n",
    "       'lr_decay_factor':0.9,\n",
    "       'lr_decay_every':5,\n",
    "       'weight_decay':1e-4,\n",
    "       'early_stopping_patience':10,\n",
    "       'early_stopping_criteria':'loss',\n",
    "       'epoch':300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ebe034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting args to series so they can be referenced the same way that argparse.ArgumentParser()\n",
    "# is reference in running a python script in the terminal\n",
    "args = pd.Series(data=[args[key] for key in args],index=[key for key in args.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b69e91",
   "metadata": {},
   "source": [
    "# Main AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31e178a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating tokenizer\n",
    "tokenizer = GloveTokenizer(f'embeddings/glove.6B.{args.embedding_size}d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce25b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train_loader, validation_loader, and test_loader\n",
    "dataset = TextLevelGNNDatasetClass(train_filename='r8-train-all-terms.txt',\n",
    "                                   test_filename='r8-test-all-terms.txt',\n",
    "                                   train_validation_split=0.8,\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   p=args.p,\n",
    "                                   min_freq=args.min_freq,\n",
    "                                   MAX_LENGTH=args.max_length)\n",
    "\n",
    "train_loader = DataLoader(dataset.train_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence)\n",
    "validation_loader = DataLoader(dataset.validation_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence)\n",
    "test_loader = DataLoader(dataset.test_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c9653b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device to cuda if gpu is available\n",
    "device = torch.device(f'cuda:{args.cuda}') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f793bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "model = TextLevelGNN(pretrained_embeddings=torch.tensor(dataset.embedding_matrix), dropout_rate=args.dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c3b94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda                            0\n",
      "embedding_size                300\n",
      "p                               3\n",
      "min_freq                        2\n",
      "max_length                     70\n",
      "dropout                         0\n",
      "lr                          0.001\n",
      "lr_decay_factor               0.9\n",
      "lr_decay_every                  5\n",
      "weight_decay               0.0001\n",
      "warm_up_epoch                   0\n",
      "early_stopping_patience        10\n",
      "early_stopping_criteria      loss\n",
      "epoch                         300\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# setting training parameters\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "lr = args.lr\n",
    "lr_decay_factor = args.lr_decay_factor\n",
    "lr_decay_every = args.lr_decay_every\n",
    "weight_decay = args.weight_decay\n",
    "\n",
    "early_stopping_patience = args.early_stopping_patience\n",
    "early_stopping_criteria = args.early_stopping_criteria\n",
    "best_epoch = 0 # Initialize\n",
    "\n",
    "training = {}\n",
    "validation = {}\n",
    "testing = {}\n",
    "training['accuracy'] = []\n",
    "training['loss'] = []\n",
    "validation['accuracy'] = []\n",
    "validation['loss'] = []\n",
    "testing['accuracy'] = []\n",
    "testing['loss'] = []\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8bccde",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c57b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 55.4425, Validation Loss: 13.1873, Testing Loss: 25.9972, Training Accuracy: 0.2826, Validation Accuracy: 0.2789, Testing Accuracy: 0.3175, Time Used: 9.48s\n",
      "Epoch: 2, Training Loss: 51.9937, Validation Loss: 13.1874, Testing Loss: 25.9974, Training Accuracy: 0.2940, Validation Accuracy: 0.2789, Testing Accuracy: 0.3175, Time Used: 9.02s\n",
      "Epoch: 3, Training Loss: 51.9943, Validation Loss: 13.1851, Testing Loss: 25.9977, Training Accuracy: 0.2938, Validation Accuracy: 0.2799, Testing Accuracy: 0.3175, Time Used: 9.01s\n",
      "Epoch: 4, Training Loss: 51.9468, Validation Loss: 13.1595, Testing Loss: 25.8962, Training Accuracy: 0.2963, Validation Accuracy: 0.2835, Testing Accuracy: 0.3234, Time Used: 9.01s\n",
      "Epoch: 5, Training Loss: 51.3057, Validation Loss: 13.0183, Testing Loss: 25.6247, Training Accuracy: 0.3191, Validation Accuracy: 0.3008, Testing Accuracy: 0.3335, Time Used: 9.03s\n",
      "Epoch: 6, Training Loss: 26.0781, Validation Loss: 4.5329, Testing Loss: 9.0667, Training Accuracy: 0.6864, Validation Accuracy: 0.8086, Testing Accuracy: 0.8090, Time Used: 9.02s\n",
      "Epoch: 7, Training Loss: 14.8475, Validation Loss: 4.0268, Testing Loss: 7.8902, Training Accuracy: 0.8136, Validation Accuracy: 0.8058, Testing Accuracy: 0.8214, Time Used: 9.02s\n",
      "Epoch: 8, Training Loss: 12.9969, Validation Loss: 3.8025, Testing Loss: 7.5218, Training Accuracy: 0.8247, Validation Accuracy: 0.8095, Testing Accuracy: 0.8232, Time Used: 9.02s\n",
      "Epoch: 9, Training Loss: 12.3273, Validation Loss: 3.5194, Testing Loss: 7.3524, Training Accuracy: 0.8320, Validation Accuracy: 0.8159, Testing Accuracy: 0.8237, Time Used: 9.02s\n",
      "Epoch: 10, Training Loss: 11.5609, Validation Loss: 3.3024, Testing Loss: 6.7866, Training Accuracy: 0.8359, Validation Accuracy: 0.8140, Testing Accuracy: 0.8296, Time Used: 9.02s\n",
      "Epoch: 11, Training Loss: 11.4698, Validation Loss: 3.4475, Testing Loss: 7.5433, Training Accuracy: 0.8336, Validation Accuracy: 0.8095, Testing Accuracy: 0.8282, Time Used: 9.02s\n",
      "Epoch: 12, Training Loss: 10.8273, Validation Loss: 3.1340, Testing Loss: 6.2215, Training Accuracy: 0.8366, Validation Accuracy: 0.8095, Testing Accuracy: 0.8314, Time Used: 9.08s\n",
      "Epoch: 13, Training Loss: 10.4620, Validation Loss: 3.0921, Testing Loss: 6.4007, Training Accuracy: 0.8389, Validation Accuracy: 0.8095, Testing Accuracy: 0.8291, Time Used: 9.12s\n",
      "Epoch: 14, Training Loss: 10.2372, Validation Loss: 3.2395, Testing Loss: 6.2288, Training Accuracy: 0.8400, Validation Accuracy: 0.8077, Testing Accuracy: 0.8328, Time Used: 9.08s\n",
      "Epoch: 15, Training Loss: 10.0917, Validation Loss: 3.1482, Testing Loss: 6.3837, Training Accuracy: 0.8407, Validation Accuracy: 0.8122, Testing Accuracy: 0.8232, Time Used: 9.05s\n",
      "Epoch: 16, Training Loss: 9.1811, Validation Loss: 2.7697, Testing Loss: 5.2219, Training Accuracy: 0.8888, Validation Accuracy: 0.8706, Testing Accuracy: 0.8917, Time Used: 9.24s\n",
      "Epoch: 17, Training Loss: 7.5944, Validation Loss: 2.4089, Testing Loss: 4.5920, Training Accuracy: 0.9079, Validation Accuracy: 0.8778, Testing Accuracy: 0.9018, Time Used: 9.21s\n",
      "Epoch: 18, Training Loss: 6.7755, Validation Loss: 2.3045, Testing Loss: 5.0332, Training Accuracy: 0.9139, Validation Accuracy: 0.8815, Testing Accuracy: 0.9050, Time Used: 9.26s\n",
      "Epoch: 19, Training Loss: 6.3797, Validation Loss: 3.7873, Testing Loss: 6.4991, Training Accuracy: 0.9166, Validation Accuracy: 0.8833, Testing Accuracy: 0.9054, Time Used: 9.10s\n",
      "Epoch: 20, Training Loss: 5.8852, Validation Loss: 2.9578, Testing Loss: 4.7673, Training Accuracy: 0.9196, Validation Accuracy: 0.8833, Testing Accuracy: 0.9114, Time Used: 9.09s\n",
      "Epoch: 21, Training Loss: 4.8763, Validation Loss: 2.4880, Testing Loss: 5.0609, Training Accuracy: 0.9540, Validation Accuracy: 0.9289, Testing Accuracy: 0.9370, Time Used: 9.20s\n",
      "Epoch: 22, Training Loss: 4.0013, Validation Loss: 3.2482, Testing Loss: 5.6011, Training Accuracy: 0.9601, Validation Accuracy: 0.9335, Testing Accuracy: 0.9402, Time Used: 9.16s\n",
      "Epoch: 23, Training Loss: 3.6130, Validation Loss: 1.7076, Testing Loss: 4.8092, Training Accuracy: 0.9624, Validation Accuracy: 0.9362, Testing Accuracy: 0.9415, Time Used: 9.15s\n",
      "Epoch: 24, Training Loss: 3.4357, Validation Loss: 3.2524, Testing Loss: 4.7848, Training Accuracy: 0.9644, Validation Accuracy: 0.9344, Testing Accuracy: 0.9392, Time Used: 9.13s\n",
      "Epoch: 25, Training Loss: 3.2494, Validation Loss: 13.3319, Testing Loss: 32.0090, Training Accuracy: 0.9660, Validation Accuracy: 0.9262, Testing Accuracy: 0.9292, Time Used: 9.15s\n",
      "Early stopping... (No further decrease in validation loss) for consecutive 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct_items = 0\n",
    "    previous_epoch_timestamp = time()\n",
    "\n",
    "    if epoch % lr_decay_every == 0: # Update optimizer for every lr_decay_every epochs\n",
    "        if epoch != 0: # When it is the first epoch, disable the lr_decay_factor\n",
    "            lr *= lr_decay_factor\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(train_loader):\n",
    "        node_sets = node_sets.to(device)\n",
    "        neighbor_sets = neighbor_sets.to(device)\n",
    "        public_edge_masks = public_edge_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # make the predictions\n",
    "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\n",
    "        # calculate loss\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        # explicitly setting the gradients to zero before starting backpropogation\n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes\n",
    "        # so the gradients need to be zeroed out, otherwise, the gradient would be a combination of the old\n",
    "        # gradient, which was already used to update the model parameters, and the newly computed gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    train_accuracy = train_correct_items / len(dataset.train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_correct_items = 0\n",
    "    for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(validation_loader):\n",
    "        node_sets = node_sets.to(device)\n",
    "        neighbor_sets = neighbor_sets.to(device)\n",
    "        public_edge_masks = public_edge_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        validation_loss += loss.item()\n",
    "        validation_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    validation_accuracy = validation_correct_items / len(dataset.validation_dataset)\n",
    "\n",
    "#     model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct_items = 0\n",
    "    for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(test_loader):\n",
    "        node_sets = node_sets.to(device)\n",
    "        neighbor_sets = neighbor_sets.to(device)\n",
    "        public_edge_masks = public_edge_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        test_loss += loss.item()\n",
    "        test_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    test_accuracy = test_correct_items / len(dataset.test_dataset)\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}, Testing Loss: {test_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {validation_accuracy:.4f}, Testing Accuracy: {test_accuracy:.4f}, Time Used: {time()-previous_epoch_timestamp:.2f}s')\n",
    "    training['accuracy'].append(train_accuracy)\n",
    "    training['loss'].append(train_loss)\n",
    "    validation['accuracy'].append(validation_accuracy)\n",
    "    validation['loss'].append(validation_loss)\n",
    "    testing['accuracy'].append(test_accuracy)\n",
    "    testing['loss'].append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb125c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(training), pd.DataFrame(validation), pd.DataFrame(testing)], axis=1)\n",
    "df.columns = ['Training Accuracy', 'Training Loss', 'Validation Accuracy', 'Validation Loss', 'Testing Accuracy', 'Testing Loss']\n",
    "df.to_csv(f'embedding_size={args.embedding_size},p={args.p},min_freq={args.min_freq},max_length={args.max_length},dropout={args.dropout},lr={args.lr},lr_decay_factor={args.lr_decay_factor},lr_decay_every={args.lr_decay_every},weight_decay={args.weight_decay},early_stopping_patience={args.early_stopping_patience},early_stopping_criteria={args.early_stopping_criteria},epoch={args.epoch}.csv') # Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6213eba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training['loss'], label='Training Loss')\n",
    "plt.plot(validation['loss'], label='Validation Loss')\n",
    "plt.plot(testing['loss'], label='Testing Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training['accuracy'], label='Training Accuracy')\n",
    "plt.plot(validation['accuracy'], label='Validation Accuracy')\n",
    "plt.plot(testing['accuracy'], label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252b110",
   "metadata": {},
   "source": [
    "# Comparison with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d0aec7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLevelNLPDatasetClass: # This class is used to achieve parameters sharing among datasets\n",
    "    def __init__(self, train_filename, test_filename, tokenizer, MAX_LENGTH=10, p=2, min_freq=2, train_validation_split=0.8):\n",
    "        print(\"Initializing TextLevelNLPDatasetClass\")\n",
    "        self.train_filename = train_filename\n",
    "        self.test_filename = test_filename\n",
    "        self.tokenizer = tokenizer\n",
    "        self.MAX_LENGTH = MAX_LENGTH\n",
    "        #self.p = p\n",
    "        #self.min_freq = min_freq\n",
    "        self.train_validation_split = train_validation_split\n",
    "\n",
    "        self.train_data = pd.read_csv(self.train_filename, sep='\\t', header=None)\n",
    "        self.test_data = pd.read_csv(self.test_filename, sep='\\t', header=None)\n",
    "\n",
    "        self.stoi = {'<unk>': 0, '<pad>': 1} # Re-index\n",
    "        self.itos = {0: '<unk>', 1: '<pad>'} # Re-index\n",
    "        self.vocab_count = len(self.stoi)\n",
    "        self.embedding_matrix = None\n",
    "        self.label_dict = dict(zip(self.train_data[0].unique(), pd.get_dummies(self.train_data[0].unique()).values.tolist()))\n",
    "\n",
    "        self.train_dataset, self.validation_dataset = random_split(self.train_data.to_numpy(), [int(len(self.train_data) * train_validation_split), len(self.train_data) - int(len(self.train_data) * train_validation_split)])\n",
    "        self.test_dataset = self.test_data.to_numpy()\n",
    "\n",
    "        self.build_vocab() # Based on train_dataset only. Updates self.stoi, self.itos, self.vocab_count and self.embedding_matrix\n",
    "\n",
    "        self.train_dataset, self.validation_dataset, self.test_dataset = self.prepare_dataset()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        print(\"Building Vocab\")\n",
    "        vocab_list = [sentence.split(' ') for _, sentence in self.train_dataset]\n",
    "        unique_vocab = []\n",
    "        for vocab in vocab_list:\n",
    "            unique_vocab.extend(vocab)\n",
    "        unique_vocab = list(set(unique_vocab))\n",
    "        for vocab in unique_vocab:\n",
    "            if vocab in self.tokenizer.stoi.keys():\n",
    "                self.stoi[vocab] = self.vocab_count\n",
    "                self.itos[self.vocab_count] = vocab\n",
    "                self.vocab_count += 1\n",
    "        self.embedding_matrix = self.tokenizer.embedding(self.tokenizer.encode(list(self.stoi.keys())))\n",
    "\n",
    "    def prepare_dataset(self): # will also build self.edge_stat and self.public_edge_mask\n",
    "        print(\"Preparing Dataset\")\n",
    "        # preparing self.train_dataset\n",
    "        # converting labels to data and converting words to numbers\n",
    "        labels = [self.label_dict[label] for label, _ in self.train_dataset]\n",
    "        train_data_encoded = [[self.stoi.get(vocab, 0) for vocab in re.findall(r\"[\\w']+|[.,!?;]\", sentence)][:self.MAX_LENGTH] for _, sentence in self.train_dataset]\n",
    "        train_dataset = TextLevelNLPDataset(train_data_encoded, labels)\n",
    "\n",
    "        # preparing self.validation_dataset\n",
    "        labels = [self.label_dict[label] for label, _ in self.validation_dataset]\n",
    "        val_data_encoded = [[self.stoi.get(vocab, 0) for vocab in re.findall(r\"[\\w']+|[.,!?;]\", sentence)][:self.MAX_LENGTH] for _, sentence in self.validation_dataset]\n",
    "        validation_dataset = TextLevelNLPDataset(val_data_encoded, labels)\n",
    "\n",
    "        # preparing self.test_dataset\n",
    "        labels = [self.label_dict[label] for label, _ in self.test_dataset]\n",
    "        test_data_encoded = [[self.stoi.get(vocab, 0) for vocab in re.findall(r\"[\\w']+|[.,!?;]\", sentence)][:self.MAX_LENGTH] for _, sentence in self.test_dataset]\n",
    "        test_dataset = TextLevelNLPDataset(test_data_encoded, labels)\n",
    "\n",
    "        return train_dataset, validation_dataset, test_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15961b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_filename, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53ea4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(train_data[0].unique(), pd.get_dummies(train_data[0].unique()).values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa73ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_split = 0.8\n",
    "train_dataset, validation_dataset = random_split(train_data.to_numpy(), [int(len(train_data) * train_validation_split), len(train_data) - int(len(train_data) * train_validation_split)])\n",
    "test_dataset = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd7a19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_dict[label] for label, _ in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86f08444",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {'<unk>': 0, '<pad>': 1} # Re-index\n",
    "itos = {0: '<unk>', 1: '<pad>'} # Re-index\n",
    "vocab_count = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6e9ba4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocab\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Vocab\")\n",
    "vocab_list = [sentence.split(' ') for _, sentence in train_dataset]\n",
    "unique_vocab = []\n",
    "for vocab in vocab_list:\n",
    "    unique_vocab.extend(vocab)\n",
    "unique_vocab = list(set(unique_vocab))\n",
    "for vocab in unique_vocab:\n",
    "    if vocab in tokenizer.stoi.keys():\n",
    "        stoi[vocab] = vocab_count\n",
    "        itos[vocab_count] = vocab\n",
    "        vocab_count += 1\n",
    "embedding_matrix = tokenizer.embedding(tokenizer.encode(list(stoi.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "03d6b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "72a191e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xyz = [[stoi.get(vocab, 0) for vocab in re.findall(r\"[\\w']+|[.,!?;]\", sentence)][:MAX_LENGTH] for _, sentence in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f3139909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2807,\n",
       " 9735,\n",
       " 52,\n",
       " 3943,\n",
       " 9886,\n",
       " 11728,\n",
       " 2807,\n",
       " 5399,\n",
       " 10430,\n",
       " 7464,\n",
       " 1761,\n",
       " 6515,\n",
       " 8197,\n",
       " 2807,\n",
       " 5399,\n",
       " 10430,\n",
       " 7464,\n",
       " 4689,\n",
       " 2863,\n",
       " 14383]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xyz[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "729582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLevelNLPDataset(Dataset): # For instantiating train, validation and test dataset\n",
    "    def __init__(self, train_data, labels):\n",
    "        super(TextLevelGNNDataset).__init__()\n",
    "        print(\"Initializing TextLevelNLPDataset\")\n",
    "        self.train_data = train_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.LongTensor(self.train_data[i]), torch.IntTensor(self.labels[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8c6b4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class TextLevelLSTM(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, out_size=8, dropout_rate=0, padding_idx=1):\n",
    "        super(TextLevelLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False) # (|V|, d)\n",
    "        self.dimension = 10\n",
    "        self.lstm = nn.LSTM(input_size=20,\n",
    "                           hidden_size=self.dimension,\n",
    "                           num_layers=1,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        self.fc = nn.Linear(2*self.dimension, 1)\n",
    "        \n",
    "    def forward(self, text, text_len=10):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "053ff898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor(sequences, padding_idx=1):\n",
    "    '''\n",
    "    To pad tensor of different shape to be of the same shape, i.e. padding [tensor.rand(2, 3), tensor.rand(3, 5)] to a shape (2, 3, 5), where 0th dimension is batch_size, 1st and 2nd dimensions are padded.\n",
    "    Input:\n",
    "        sequences <list>: A list of tensors\n",
    "        padding_idx <int>: The index that corresponds to the padding index\n",
    "    Return:\n",
    "        out_tensor <torch.tensor>: The padded tensor\n",
    "        mask <torch.tensor>: A boolean torch tensor where 1 (represents '<pad>') are marked as true\n",
    "    '''\n",
    "    num = len(sequences)\n",
    "    max_len_0 = max([s.shape[0] for s in sequences])\n",
    "    #max_len_1 = max([s.shape[1] for s in sequences])\n",
    "    out_dims = (num, max_len_0)\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_idx)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        len_0 = tensor.size(0)\n",
    "        #len_1 = tensor.size(1)\n",
    "        out_tensor[i, :len_0] = tensor\n",
    "    mask = out_tensor == padding_idx # Marking all places with padding_idx as mask\n",
    "    return out_tensor, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "352b57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_custom_sequence_NLP(sequences):\n",
    "    texts_sequence = []\n",
    "    label_sequence = []\n",
    "    \n",
    "    for text_set, label_set in sequences:\n",
    "        texts_sequence.append(text_set)\n",
    "        label_sequence.append(label_set)\n",
    "    #texts_sequence = torch.nn.utils.rnn.pad_sequence(texts_sequence, batch_first=True, padding_value=1)\n",
    "    texts_sequence, _ = padding_tensor(texts_sequence)\n",
    "    label_sequence, _ = padding_tensor(label_sequence)\n",
    "    return texts_sequence, label_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "44d07a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = GloveTokenizer(f'embeddings/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f8f08a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TextLevelNLPDatasetClass\n",
      "Building Vocab\n",
      "Preparing Dataset\n",
      "Initializing TextLevelNLPDataset\n",
      "Initializing TextLevelNLPDataset\n",
      "Initializing TextLevelNLPDataset\n"
     ]
    }
   ],
   "source": [
    "dataset = TextLevelNLPDatasetClass(train_filename='r8-train-all-terms.txt',\n",
    "                                   test_filename='r8-test-all-terms.txt',\n",
    "                                   train_validation_split=0.8,\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   MAX_LENGTH=10)\n",
    "train_loader = DataLoader(dataset.train_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence_NLP)\n",
    "validation_loader = DataLoader(dataset.validation_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence_NLP)\n",
    "test_loader = DataLoader(dataset.test_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence_NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "20a6bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 7058, 10837, 11294, 12527, 12669,  7332,  7979,  2337,  7979,  2251]), tensor([0, 0, 1, 0, 0, 0, 0, 0], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "for ind, item in enumerate(dataset.train_dataset):\n",
    "    #print(ind)\n",
    "    if ind == 0:\n",
    "        print(item)\n",
    "\n",
    "    #print(len(item[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b654e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[12665,  4788,  5978, 12155,  7773,  6987, 11428,  1766,  4250,  5427],\n",
      "        [ 1862,  8008,     0, 13526, 11905,     0, 12676,  2251, 10323,  2251],\n",
      "        [ 7442, 13314, 12866,  1589,  8654,  3969,     0,  7442, 13314,  9545],\n",
      "        [  995,  7606, 11129, 12919, 14675,  8072,  7425,  1766,  6752,   867],\n",
      "        [ 1246,  9465,  4766,  8153,  1592,  9713,  5008, 13513,  9545,  6539],\n",
      "        [ 3594,  6512,  9545,  9638, 14955,  1668,  1129, 14564,  3371,     1],\n",
      "        [ 4232,  6861, 15002, 13115, 14947,  4232,  6861,  9545,  9812,  8057],\n",
      "        [11320, 13314, 13371, 11294,     0, 12669,  7332,  9548, 14980,  2337],\n",
      "        [ 5966, 11294,     0,  3121, 10647,  3155,     0, 12676,  2251, 10323],\n",
      "        [    0,  1783,  9433,  8646, 11496, 14980,  2337,  6978, 13401,  2251],\n",
      "        [13643, 10505,  3760,  9545,  8795, 13526, 11905,     0, 12676,  2251],\n",
      "        [ 4440, 12155,  8461,  6539, 11438,   263,  8798, 12738,     7, 13145],\n",
      "        [ 2502,  2058, 15325, 13993,  2465,  3356,  8550,    53,  8885,   324],\n",
      "        [ 5788, 12654,  4440, 12155, 14882,  4250, 13047,  1337,  1766,  8569],\n",
      "        [14976,  9265,  9871,  5058,   162, 12253, 11158, 14976,  5425,  8531],\n",
      "        [ 9628,  4391, 13513, 11294,     0, 10576,  7332,  2337,  2251, 10323],\n",
      "        [ 5058,     0,    53,  8885,  3919,  4713,  8875,  5610,  5058,  1783],\n",
      "        [ 5894,  9051,     0,  8153,   120,  5894,  9051, 13513,  9545,  6539],\n",
      "        [  563,  1966,  9430, 12086,  3863, 12556,  9690, 13373, 12155,   122],\n",
      "        [  535, 13370, 14882, 12331,    53, 10334,  2092,  3438,  6928,   535],\n",
      "        [    0,  7907, 11294,     0, 12669,  7332, 14980, 15308,  2337,  6978],\n",
      "        [ 1777, 12298, 12887, 12922,  7282, 11555, 12676,     0, 12676, 13639],\n",
      "        [10498,   295,  5425,  4871, 10215,     0,  1499,  8588,   295,  4713],\n",
      "        [ 7349,  8572,  8646,  7269, 14361,  9890,  2165,  4406,  3255, 14675],\n",
      "        [ 5624,  3598, 10266,  6017,  8506,  3486,  4480,  6728,  9451,  5719],\n",
      "        [11937, 10191,  9545,  9690, 14637, 11937, 10191,  9545,  6539, 13993],\n",
      "        [13344,   295, 13686,  2576,   248,  1499,    53,  3919,  8588,   295],\n",
      "        [  417, 11294,  5914,  1995, 11905,     0, 12676,  4595,  2251, 10323],\n",
      "        [11576, 10750,  9545,     0,  4975,  7332, 14980,  2337,  2251, 10323],\n",
      "        [ 5133,  5133, 10191,  8539, 12669,  7332, 14980, 15308,  2337,  2251],\n",
      "        [13614, 10618,  2600,  9545, 13370,    53,  4308, 11428,  8057,  8863],\n",
      "        [11058,  8811, 14388,  8646,  7979,  2337,  7979,  6252, 10323,  6978]]), tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0]], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "for ind, item in enumerate(train_loader):\n",
    "    if ind == 1:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "32e5fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{args.cuda}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = TextLevelLSTM(pretrained_embeddings=torch.tensor(dataset.embedding_matrix), dropout_rate=0.5).to(device)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "be99115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = args.lr\n",
    "lr_decay_factor = args.lr_decay_factor\n",
    "lr_decay_every = args.lr_decay_every\n",
    "weight_decay = args.weight_decay\n",
    "\n",
    "early_stopping_patience = args.early_stopping_patience\n",
    "early_stopping_criteria = args.early_stopping_criteria\n",
    "best_epoch = 0 # Initialize\n",
    "\n",
    "training = {}\n",
    "validation = {}\n",
    "testing = {}\n",
    "training['accuracy'] = []\n",
    "training['loss'] = []\n",
    "validation['accuracy'] = []\n",
    "validation['loss'] = []\n",
    "testing['accuracy'] = []\n",
    "testing['loss'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "63f44e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'lengths' argument should be a 1D CPU int64 tensor, but got 0D cpu Long tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5833/1939739471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graphgym/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5833/4097020941.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_len)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtext_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graphgym/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 0D cpu Long tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct_items = 0\n",
    "    previous_epoch_timestamp = time()\n",
    "\n",
    "    if epoch % lr_decay_every == 0: # Update optimizer for every lr_decay_every epochs\n",
    "        if epoch != 0: # When it is the first epoch, disable the lr_decay_factor\n",
    "            lr *= lr_decay_factor\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for i, (train_sets, labels) in enumerate(train_loader):\n",
    "#         print('Finished batch:', i)\n",
    "        train_sets = train_sets.to(device)\n",
    "        labels = labels.to(device)\n",
    "        prediction = model(train_sets)\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    train_accuracy = train_correct_items / len(dataset.train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_correct_items = 0\n",
    "    for i, (val_sets, labels) in enumerate(validation_loader):\n",
    "        val_sets = val_sets.to(device)\n",
    "        labels = labels.to(device)\n",
    "        prediction = model(val_sets, public_edge_masks)\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        validation_loss += loss.item()\n",
    "        validation_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    validation_accuracy = validation_correct_items / len(dataset.validation_dataset)\n",
    "\n",
    "#     model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct_items = 0\n",
    "    for i, (test_sets, labels) in enumerate(test_loader):\n",
    "        test_sets = test_sets.to(device)\n",
    "        labels = labels.to(device)\n",
    "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\n",
    "        loss = criterion(prediction, labels).to(device)\n",
    "        test_loss += loss.item()\n",
    "        test_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    test_accuracy = test_correct_items / len(dataset.test_dataset)\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}, Testing Loss: {test_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {validation_accuracy:.4f}, Testing Accuracy: {test_accuracy:.4f}, Time Used: {time()-previous_epoch_timestamp:.2f}s')\n",
    "    training['accuracy'].append(train_accuracy)\n",
    "    training['loss'].append(train_loss)\n",
    "    validation['accuracy'].append(validation_accuracy)\n",
    "    validation['loss'].append(validation_loss)\n",
    "    testing['accuracy'].append(test_accuracy)\n",
    "    testing['loss'].append(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebe512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
